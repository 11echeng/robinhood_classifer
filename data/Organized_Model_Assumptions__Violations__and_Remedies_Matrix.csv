Model,Assumptions,Violations and Remedies
Logistic Regression,"Linearity of log-odds, Independence of observations, No multicollinearity, Homoscedasticity in log-odds, Requires large sample size.","Non-linearity (transform variables), Multicollinearity (PCA/removal), Imbalanced Data (SMOTE, class weights), Outliers (remove or transform)."
XGBoost,"No assumptions about data distribution, Handles non-linearity, Independence of observations.","Overfitting (regularization, tree depth), High cardinality (one-hot/target encoding), Imbalanced Data (scale_pos_weight/class weights)."
LightGBM,"No assumptions about data distribution, Handles non-linearity, Independence of observations.","Overfitting (regularization, tune num_leaves/max_depth), Imbalanced Data (scale_pos_weight/class weights), High cardinality (limit feature levels)."
Random Forest,"No assumptions about data distribution, Handles non-linearity, Independence of observations.","Overfitting (limit trees/max depth), Imbalanced Data (class weights/resampling), Missing Data (imputation), Multicollinearity (remove redundant features)."
PyTorch (Neural Networks),"No assumptions about data distribution, Handles non-linearity, Independence of observations (except in RNNs, LSTMs).","Overfitting (dropout, L2 regularization), Imbalanced Data (class weights/resampling), Large Data (use early stopping, transfer learning), Normalization (MinMax, StandardScaler)."
